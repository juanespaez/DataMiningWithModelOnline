{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# === Celda 1: Crear pipeline con StandardScaler ya ajustado y guardar ===\n",
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Rutas (ajusta si usas otras)\n",
        "PATH_DF = '/content/df_limpio_modelo.csv'              # CSV usado en entrenamiento (contiene 'target')\n",
        "MODEL_FILE = '/content/mejor_modelo_AdaBoost.pkl'      # tu modelo AdaBoost entrenado\n",
        "OUT_PIPE = '/content/modelo_final_pipeline.pkl'       # pipeline resultante (salida)\n",
        "\n",
        "# 1) Chequeos iniciales\n",
        "for p in [PATH_DF, MODEL_FILE]:\n",
        "    if not os.path.exists(p):\n",
        "        raise FileNotFoundError(f\"No se encontr√≥ el archivo requerido: {p}. S√∫belo a /content y vuelve a ejecutar.\")\n",
        "\n",
        "# 2) Cargar datos de entrenamiento y obtener X (sin target)\n",
        "df = pd.read_csv(PATH_DF)\n",
        "if 'target' not in df.columns:\n",
        "    raise KeyError(\"El CSV de entrenamiento debe contener la columna 'target'. Cambia el nombre o actualiza el CSV.\")\n",
        "X = df.drop(columns=['target'])\n",
        "feature_names = X.columns.tolist()\n",
        "print(\"‚úÖ Columnas (features) detectadas:\", feature_names)\n",
        "\n",
        "# 3) Cargar el estimador AdaBoost (o pipeline que contiene solo el modelo)\n",
        "modelo = joblib.load(MODEL_FILE)\n",
        "print(\"‚úÖ Modelo cargado:\", type(modelo).__name__)\n",
        "\n",
        "# 4) Ajustar el scaler en los datos originales (sin modificar el modelo)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "print(\"‚úÖ StandardScaler ajustado con los datos de entrenamiento.\")\n",
        "\n",
        "# 5) Crear pipeline final (scaler ya ajustado + modelo)\n",
        "pipeline_completo = Pipeline([\n",
        "    ('scaler', scaler),\n",
        "    ('model', modelo)\n",
        "])\n",
        "\n",
        "# 6) Guardar pipeline completo\n",
        "joblib.dump(pipeline_completo, OUT_PIPE)\n",
        "print(f\"‚úÖ Pipeline completo guardado en: {OUT_PIPE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JETxg8gJ8fxa",
        "outputId": "26d4cbdd-28c0-4b7b-b032-130bf19355f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Columnas (features) detectadas: ['age', 'sex', 'thalach', 'exang', 'oldpeak', 'ca', 'risk_index', 'age_thalach_interaction', 'oldpeak_ca_ratio', 'cp_1', 'cp_2', 'cp_3', 'restecg_1', 'restecg_2', 'thal_1', 'thal_2', 'thal_3', 'age_group_middle', 'age_group_senior']\n",
            "‚úÖ Modelo cargado: AdaBoostClassifier\n",
            "‚úÖ StandardScaler ajustado con los datos de entrenamiento.\n",
            "‚úÖ Pipeline completo guardado en: /content/modelo_final_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Celda 2: Cargar pipeline y predecir sobre nuevos_datos.csv (verifica columnas y orden) ===\n",
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "\n",
        "PIPE_PATH = '/content/modelo_final_pipeline.pkl'  # archivo creado en la Celda 1\n",
        "NUEVOS_CSV = '/content/nuevos_datos.csv'          # CSV con nuevos ejemplos a predecir\n",
        "DF_ENTRENAMIENTO = '/content/df_limpio_modelo.csv' # para recuperar el orden de columnas usadas\n",
        "\n",
        "# Comprobaciones\n",
        "if not os.path.exists(PIPE_PATH):\n",
        "    raise FileNotFoundError(f\"No se encontr√≥ el pipeline en: {PIPE_PATH}. Ejecuta la celda 1 primero.\")\n",
        "if not os.path.exists(NUEVOS_CSV):\n",
        "    raise FileNotFoundError(f\"No se encontr√≥ {NUEVOS_CSV}. Sube tus datos nuevos a /content/nuevos_datos.csv\")\n",
        "\n",
        "# Cargar pipeline\n",
        "pipe = joblib.load(PIPE_PATH)\n",
        "print(\"‚úÖ Pipeline cargado:\", PIPE_PATH)\n",
        "\n",
        "# Recuperar columnas (orden correcto) desde el CSV de entrenamiento\n",
        "if not os.path.exists(DF_ENTRENAMIENTO):\n",
        "    raise FileNotFoundError(f\"No se encontr√≥ {DF_ENTRENAMIENTO}. Necesitamos el CSV de entrenamiento para conocer el orden de columnas.\")\n",
        "df_train = pd.read_csv(DF_ENTRENAMIENTO)\n",
        "if 'target' not in df_train.columns:\n",
        "    raise KeyError(\"df_limpio_modelo.csv debe contener la columna 'target'.\")\n",
        "expected_features = df_train.drop(columns=['target']).columns.tolist()\n",
        "print(\"‚úÖ Columnas esperadas (en orden):\", expected_features)\n",
        "\n",
        "# Cargar nuevos datos\n",
        "nuevos = pd.read_csv(NUEVOS_CSV)\n",
        "print(\"Nuevos datos le√≠dos. Shape:\", nuevos.shape)\n",
        "print(\"Columnas en nuevos_datos.csv:\", nuevos.columns.tolist())\n",
        "\n",
        "# Verificar que todos los features esperados est√©n presentes\n",
        "missing = [c for c in expected_features if c not in nuevos.columns]\n",
        "if missing:\n",
        "    raise KeyError(f\"Faltan columnas en nuevos_datos.csv que el modelo espera: {missing}\")\n",
        "\n",
        "# Reordenar y seleccionar solo las columnas esperadas (esto evita problemas de orden)\n",
        "nuevos_alineados = nuevos[expected_features].copy()\n",
        "print(\"‚úÖ Nuevos datos alineados con el orden de entrenamiento. Shape:\", nuevos_alineados.shape)\n",
        "\n",
        "# Realizar predicciones\n",
        "try:\n",
        "    preds = pipe.predict(nuevos_alineados)\n",
        "    # Si el pipeline soporta predict_proba, tambi√©n mostrar probabilidades (opc.)\n",
        "    probs = None\n",
        "    if hasattr(pipe, \"predict_proba\"):\n",
        "        try:\n",
        "            probs = pipe.predict_proba(nuevos_alineados)\n",
        "        except Exception:\n",
        "            probs = None\n",
        "\n",
        "    print(\"‚úÖ Predicciones realizadas. Ejemplo (primeras 10):\", preds[:10])\n",
        "    if probs is not None:\n",
        "        print(\"‚úÖ Ejemplo de probabilidades (primeras 3 filas):\")\n",
        "        print(probs[:3])\n",
        "\n",
        "    # Guardar resultados junto a los datos de entrada\n",
        "    resultados = nuevos_alineados.copy()\n",
        "    resultados['prediction'] = preds\n",
        "    # si probs existe y tiene 2 columnas (binario), a√±adir probabilidad positiva\n",
        "    if probs is not None and probs.shape[1] == 2:\n",
        "        resultados['probabilidad_positiva'] = probs[:, 1]\n",
        "\n",
        "    out_file = '/content/predicciones_resultado.csv'\n",
        "    resultados.to_csv(out_file, index=False)\n",
        "    print(f\"‚úÖ Resultados guardados en: {out_file}\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Error durante la predicci√≥n: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIB-sU9IEbRa",
        "outputId": "cba37c7a-06a4-4b6d-9e4b-000544500cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Pipeline cargado: /content/modelo_final_pipeline.pkl\n",
            "‚úÖ Columnas esperadas (en orden): ['age', 'sex', 'thalach', 'exang', 'oldpeak', 'ca', 'risk_index', 'age_thalach_interaction', 'oldpeak_ca_ratio', 'cp_1', 'cp_2', 'cp_3', 'restecg_1', 'restecg_2', 'thal_1', 'thal_2', 'thal_3', 'age_group_middle', 'age_group_senior']\n",
            "Nuevos datos le√≠dos. Shape: (10, 20)\n",
            "Columnas en nuevos_datos.csv: ['age', 'sex', 'thalach', 'exang', 'oldpeak', 'ca', 'target', 'risk_index', 'age_thalach_interaction', 'oldpeak_ca_ratio', 'cp_1', 'cp_2', 'cp_3', 'restecg_1', 'restecg_2', 'thal_1', 'thal_2', 'thal_3', 'age_group_middle', 'age_group_senior']\n",
            "‚úÖ Nuevos datos alineados con el orden de entrenamiento. Shape: (10, 19)\n",
            "‚úÖ Predicciones realizadas. Ejemplo (primeras 10): [0 1 0 1 1 0 1 0 1 1]\n",
            "‚úÖ Ejemplo de probabilidades (primeras 3 filas):\n",
            "[[0.86772889 0.13227111]\n",
            " [0.18948607 0.81051393]\n",
            " [0.86772889 0.13227111]]\n",
            "‚úÖ Resultados guardados en: /content/predicciones_resultado.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAxQvBBt_QOJ",
        "outputId": "e11bf697-6ccb-4060-dfb3-6943de3ec594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.4.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import os\n",
        "import datetime\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Config\n",
        "MODEL_PATH = '/content/modelo_final_pipeline.pkl'\n",
        "DF_TRAIN_PATH = '/content/df_limpio_modelo.csv'\n",
        "PREDICTIONS_OUT = '/content/predicciones_resultado.csv'\n",
        "VALIDATION_EVIDENCE = '/content/evidencia_validacion_predicciones.csv'\n",
        "LOGFILE = '/content/prediction_log.csv'\n",
        "\n",
        "# Configuraci√≥n de p√°gina con tema personalizado\n",
        "st.set_page_config(\n",
        "    page_title=\"Predicci√≥n AdaBoost\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# CSS personalizado para dise√±o moderno\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "/* Fondo general */\n",
        ".stApp {\n",
        "    background-color: #f9fafb;\n",
        "}\n",
        "\n",
        "/* Contenedor principal */\n",
        ".main .block-container {\n",
        "    background: white;\n",
        "    border-radius: 18px;\n",
        "    padding: 2rem;\n",
        "    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.05);\n",
        "}\n",
        "\n",
        "/* T√≠tulo principal */\n",
        ".main-title {\n",
        "    color: #1f2937;\n",
        "    font-size: 2.5rem;\n",
        "    font-weight: 800;\n",
        "    text-align: center;\n",
        "    margin-bottom: 0.5rem;\n",
        "}\n",
        "\n",
        "/* Subt√≠tulo */\n",
        ".subtitle {\n",
        "    text-align: center;\n",
        "    font-size: 1.1rem;\n",
        "    color: #6b7280;\n",
        "    margin-bottom: 2rem;\n",
        "}\n",
        "\n",
        "/* Cards */\n",
        ".card {\n",
        "    background: #ffffff;\n",
        "    border-radius: 12px;\n",
        "    padding: 1.5rem;\n",
        "    margin: 1rem 0;\n",
        "    border: 1px solid #e5e7eb;\n",
        "    transition: all 0.3s ease;\n",
        "}\n",
        ".card:hover {\n",
        "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
        "}\n",
        "\n",
        "/* M√©tricas */\n",
        ".metric-container {\n",
        "    background: #4f46e5;\n",
        "    border-radius: 10px;\n",
        "    padding: 1rem;\n",
        "    color: white;\n",
        "    text-align: center;\n",
        "    margin: 0.5rem;\n",
        "}\n",
        ".metric-value {\n",
        "    font-size: 2rem;\n",
        "    font-weight: bold;\n",
        "}\n",
        ".metric-label {\n",
        "    font-size: 0.9rem;\n",
        "    text-transform: uppercase;\n",
        "    letter-spacing: 1px;\n",
        "    opacity: 0.9;\n",
        "}\n",
        "\n",
        "/* Botones */\n",
        ".stButton>button {\n",
        "    background: #4f46e5;\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 8px;\n",
        "    padding: 0.6rem 1.5rem;\n",
        "    font-weight: 600;\n",
        "    transition: all 0.3s ease;\n",
        "}\n",
        ".stButton>button:hover {\n",
        "    background: #4338ca;\n",
        "    transform: translateY(-2px);\n",
        "}\n",
        "\n",
        "/* Inputs */\n",
        ".stNumberInput>div>div>input {\n",
        "    border-radius: 8px;\n",
        "    border: 1px solid #d1d5db;\n",
        "}\n",
        ".stNumberInput>div>div>input:focus {\n",
        "    border-color: #4f46e5;\n",
        "    box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.2);\n",
        "}\n",
        "\n",
        "/* Tabs */\n",
        ".stTabs [data-baseweb=\"tab-list\"] {\n",
        "    background-color: #f3f4f6;\n",
        "    border-radius: 8px;\n",
        "    padding: 0.4rem;\n",
        "    gap: 6px;\n",
        "}\n",
        ".stTabs [data-baseweb=\"tab\"] {\n",
        "    border-radius: 6px;\n",
        "    padding: 0.4rem 1rem;\n",
        "    font-weight: 600;\n",
        "    color: #374151;\n",
        "}\n",
        ".stTabs [aria-selected=\"true\"] {\n",
        "    background-color: #4f46e5 !important;\n",
        "    color: white !important;\n",
        "}\n",
        "\n",
        "/* File uploader */\n",
        ".stFileUploader>div>div {\n",
        "    border-radius: 10px;\n",
        "    border: 2px dashed #a5b4fc;\n",
        "    background: #f8fafc;\n",
        "}\n",
        "\n",
        "/* Expander */\n",
        ".streamlit-expanderHeader {\n",
        "    background: #4f46e5;\n",
        "    color: white;\n",
        "    border-radius: 8px;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        "/* Footer */\n",
        ".footer {\n",
        "    text-align: center;\n",
        "    color: #6b7280;\n",
        "    font-size: 0.9rem;\n",
        "    padding: 1.5rem 0;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# Helper: append log\n",
        "def append_log(input_df, prediction, probs=None):\n",
        "    df = input_df.copy()\n",
        "    df['prediction'] = prediction\n",
        "    if probs is not None and getattr(probs, 'shape', None) and probs.shape[1] == 2:\n",
        "        df['prob_pos'] = probs[:, 1]\n",
        "    df['timestamp'] = datetime.datetime.utcnow().isoformat()\n",
        "    header = not os.path.exists(LOGFILE)\n",
        "    df.to_csv(LOGFILE, mode='a', header=header, index=False)\n",
        "    return LOGFILE\n",
        "\n",
        "# Header con dise√±o moderno\n",
        "st.markdown('<h1 class=\"main-title\">üîÆ Predicci√≥n de datos futuros</h1>', unsafe_allow_html=True)\n",
        "st.markdown('<p style=\"text-align: center; font-size: 1.2rem; color: #666; margin-bottom: 2rem;\">Sistema de predicci√≥n avanzado con AdaBoost</p>', unsafe_allow_html=True)\n",
        "\n",
        "# Load pipeline con indicador visual mejorado\n",
        "pipe = None\n",
        "with st.spinner('üîÑ Cargando modelo...'):\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        st.error(f\"‚ùå Modelo no encontrado en: {MODEL_PATH}. Sube 'modelo_final_pipeline.pkl' a /content\")\n",
        "    else:\n",
        "        try:\n",
        "            pipe = joblib.load(MODEL_PATH)\n",
        "            st.success(\"‚úÖ Pipeline cargado correctamente\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå Error cargando el modelo: {e}\")\n",
        "            pipe = None\n",
        "\n",
        "# Infer feature names from training CSV if available\n",
        "def get_feature_names():\n",
        "    if os.path.exists(DF_TRAIN_PATH):\n",
        "        try:\n",
        "            df_train = pd.read_csv(DF_TRAIN_PATH)\n",
        "            if 'target' in df_train.columns:\n",
        "                return df_train.drop(columns=['target']).columns.tolist()\n",
        "            else:\n",
        "                return df_train.columns.tolist()\n",
        "        except Exception:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "feature_names = get_feature_names() or ['col1', 'col2', 'col3', 'col4']\n",
        "\n",
        "# Tabs principales para mejor organizaci√≥n\n",
        "tab1, tab2, tab3 = st.tabs([\"üî¢ Predicci√≥n Manual\", \"üìÅ Predicci√≥n por Lote\", \"üß™ Validaci√≥n\"])\n",
        "\n",
        "# TAB 1: Entrada manual\n",
        "with tab1:\n",
        "    if pipe is not None:\n",
        "        st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
        "        st.subheader(\"üìù Entrada manual de datos\")\n",
        "        st.write(\"Ingresa valores para cada feature y obt√©n una predicci√≥n instant√°nea\")\n",
        "\n",
        "        # Organizar inputs en columnas\n",
        "        cols_per_row = 3\n",
        "        inputs = {}\n",
        "\n",
        "        for i in range(0, len(feature_names), cols_per_row):\n",
        "            cols = st.columns(cols_per_row)\n",
        "            for j, col in enumerate(cols):\n",
        "                if i + j < len(feature_names):\n",
        "                    feature = feature_names[i + j]\n",
        "                    with col:\n",
        "                        inputs[feature] = st.number_input(\n",
        "                            f\"üìä {feature}\",\n",
        "                            value=0.0,\n",
        "                            format=\"%.6f\",\n",
        "                            key=f\"manual_{feature}\"\n",
        "                        )\n",
        "\n",
        "        input_df = pd.DataFrame([inputs])\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        col1, col2, col3 = st.columns([1, 2, 1])\n",
        "        with col2:\n",
        "            if st.button(\"üöÄ Predecir\", use_container_width=True):\n",
        "                with st.spinner('Calculando predicci√≥n...'):\n",
        "                    try:\n",
        "                        pred = pipe.predict(input_df)\n",
        "                        probs = None\n",
        "                        try:\n",
        "                            if hasattr(pipe, 'predict_proba'):\n",
        "                                probs = pipe.predict_proba(input_df)\n",
        "                        except Exception:\n",
        "                            probs = None\n",
        "\n",
        "                        # Mostrar resultado con dise√±o atractivo\n",
        "                        st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
        "                        col1, col2 = st.columns(2)\n",
        "\n",
        "                        with col1:\n",
        "                            st.markdown(f\"\"\"\n",
        "                            <div class=\"metric-container\">\n",
        "                                <div class=\"metric-label\">Predicci√≥n</div>\n",
        "                                <div class=\"metric-value\">{pred[0]}</div>\n",
        "                            </div>\n",
        "                            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                        with col2:\n",
        "                            if probs is not None and probs.shape[1] == 2:\n",
        "                                st.markdown(f\"\"\"\n",
        "                                <div class=\"metric-container\">\n",
        "                                    <div class=\"metric-label\">Probabilidad</div>\n",
        "                                    <div class=\"metric-value\">{probs[0,1]:.2%}</div>\n",
        "                                </div>\n",
        "                                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "                        # Log\n",
        "                        logpath = append_log(input_df, pred, probs)\n",
        "                        st.info(f\"üìù Registro guardado en: {logpath}\")\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"‚ùå Error durante la predicci√≥n: {e}\")\n",
        "    else:\n",
        "        st.warning(\"‚ö†Ô∏è Por favor, carga el modelo primero\")\n",
        "\n",
        "# TAB 2: Batch predictions\n",
        "with tab2:\n",
        "    st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
        "    st.subheader(\"üì§ Carga tu archivo CSV\")\n",
        "    st.write(\"Sube un archivo con m√∫ltiples registros para predicci√≥n masiva\")\n",
        "\n",
        "    uploaded = st.file_uploader(\n",
        "        \"Arrastra tu archivo o haz clic para seleccionar\",\n",
        "        type=['csv'],\n",
        "        help=\"El archivo debe contener las mismas columnas que el dataset de entrenamiento\"\n",
        "    )\n",
        "\n",
        "    if uploaded is not None and pipe is not None:\n",
        "        try:\n",
        "            df_new = pd.read_csv(uploaded)\n",
        "\n",
        "            # Mostrar preview del archivo\n",
        "            with st.expander(\"üëÅÔ∏è Vista previa del archivo\", expanded=True):\n",
        "                st.dataframe(df_new.head(10), use_container_width=True)\n",
        "                st.write(f\"üìä Dimensiones: {df_new.shape[0]} filas √ó {df_new.shape[1]} columnas\")\n",
        "\n",
        "            # Align columns\n",
        "            expected = feature_names\n",
        "            missing = [c for c in expected if c not in df_new.columns]\n",
        "\n",
        "            if missing:\n",
        "                st.error(f\"‚ùå Faltan columnas: {', '.join(missing)}\")\n",
        "            else:\n",
        "                df_aligned = df_new[expected].copy()\n",
        "\n",
        "                col1, col2, col3 = st.columns([1, 2, 1])\n",
        "                with col2:\n",
        "                    if st.button(\"üéØ Predecir lote y guardar resultados\", use_container_width=True):\n",
        "                        with st.spinner('‚è≥ Procesando predicciones...'):\n",
        "                            try:\n",
        "                                preds = pipe.predict(df_aligned)\n",
        "                                probs = None\n",
        "                                try:\n",
        "                                    if hasattr(pipe, 'predict_proba'):\n",
        "                                        probs = pipe.predict_proba(df_aligned)\n",
        "                                except Exception:\n",
        "                                    probs = None\n",
        "\n",
        "                                outdf = df_aligned.copy()\n",
        "                                outdf['prediction'] = preds\n",
        "                                if probs is not None and probs.shape[1] == 2:\n",
        "                                    outdf['prob_pos'] = probs[:,1]\n",
        "\n",
        "                                outdf.to_csv(PREDICTIONS_OUT, index=False)\n",
        "                                append_log(df_aligned, preds, probs)\n",
        "\n",
        "                                st.success(f\"‚úÖ Predicciones guardadas en: {PREDICTIONS_OUT}\")\n",
        "\n",
        "                                # Mostrar estad√≠sticas\n",
        "                                col1, col2, col3 = st.columns(3)\n",
        "                                with col1:\n",
        "                                    st.metric(\"Total predicciones\", len(preds))\n",
        "                                with col2:\n",
        "                                    st.metric(\"Clase 0\", (preds == 0).sum())\n",
        "                                with col3:\n",
        "                                    st.metric(\"Clase 1\", (preds == 1).sum())\n",
        "\n",
        "                                st.download_button(\n",
        "                                    \"‚¨áÔ∏è Descargar predicciones (CSV)\",\n",
        "                                    data=outdf.to_csv(index=False).encode('utf-8'),\n",
        "                                    file_name='predicciones_resultado.csv',\n",
        "                                    mime='text/csv',\n",
        "                                    use_container_width=True\n",
        "                                )\n",
        "                            except Exception as e:\n",
        "                                st.error(f\"‚ùå Error durante predicci√≥n por lote: {e}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå Error leyendo el CSV: {e}\")\n",
        "\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "# TAB 3: Validation\n",
        "with tab3:\n",
        "    if pipe is None:\n",
        "        st.info(\"‚ö†Ô∏è Carga el pipeline para usar el modo de validaci√≥n\")\n",
        "    else:\n",
        "        st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
        "        st.subheader(\"üéØ Validaci√≥n del modelo\")\n",
        "        st.write(\"Eval√∫a el rendimiento del modelo con datos etiquetados\")\n",
        "\n",
        "        uploaded_test = st.file_uploader(\n",
        "            \"Sube un CSV de test (debe contener 'target')\",\n",
        "            type=['csv'],\n",
        "            key='test_upload',\n",
        "            help=\"El archivo debe incluir la columna 'target' con las etiquetas reales\"\n",
        "        )\n",
        "\n",
        "        use_uploaded = uploaded_test is not None\n",
        "\n",
        "        if use_uploaded:\n",
        "            df_test = pd.read_csv(uploaded_test)\n",
        "        elif os.path.exists('/content/test_para_validacion.csv'):\n",
        "            df_test = pd.read_csv('/content/test_para_validacion.csv')\n",
        "            st.info(\"üìÇ Usando archivo de test por defecto\")\n",
        "        else:\n",
        "            df_test = None\n",
        "\n",
        "        if df_test is not None:\n",
        "            with st.expander(\"üëÅÔ∏è Vista previa del dataset de test\", expanded=False):\n",
        "                st.dataframe(df_test.head(10), use_container_width=True)\n",
        "\n",
        "            if 'target' not in df_test.columns:\n",
        "                st.error(\"‚ùå El dataset de validaci√≥n debe incluir la columna 'target'\")\n",
        "            else:\n",
        "                missing = [c for c in feature_names if c not in df_test.columns]\n",
        "                if missing:\n",
        "                    st.error(f\"‚ùå Faltan columnas en dataset de test: {', '.join(missing)}\")\n",
        "                else:\n",
        "                    X_test = df_test[feature_names].copy()\n",
        "                    y_test = df_test['target'].copy()\n",
        "\n",
        "                    col1, col2, col3 = st.columns([1, 2, 1])\n",
        "                    with col2:\n",
        "                        if st.button(\"üßÆ Correr validaci√≥n y calcular m√©tricas\", use_container_width=True):\n",
        "                            with st.spinner('üìä Calculando m√©tricas...'):\n",
        "                                try:\n",
        "                                    preds = pipe.predict(X_test)\n",
        "                                    probs = None\n",
        "                                    try:\n",
        "                                        if hasattr(pipe, 'predict_proba'):\n",
        "                                            probs = pipe.predict_proba(X_test)\n",
        "                                    except Exception:\n",
        "                                        probs = None\n",
        "\n",
        "                                    acc = accuracy_score(y_test, preds)\n",
        "                                    prec = precision_score(y_test, preds, zero_division=0)\n",
        "                                    rec = recall_score(y_test, preds, zero_division=0)\n",
        "                                    f1s = f1_score(y_test, preds, zero_division=0)\n",
        "                                    cm = confusion_matrix(y_test, preds)\n",
        "                                    report = classification_report(y_test, preds, zero_division=0)\n",
        "\n",
        "                                    st.markdown(\"---\")\n",
        "                                    st.subheader(\"üìà Resultados de Validaci√≥n\")\n",
        "\n",
        "                                    # M√©tricas en tarjetas\n",
        "                                    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "                                    with col1:\n",
        "                                        st.markdown(f\"\"\"\n",
        "                                        <div class=\"metric-container\">\n",
        "                                            <div class=\"metric-label\">Accuracy</div>\n",
        "                                            <div class=\"metric-value\">{acc:.2%}</div>\n",
        "                                        </div>\n",
        "                                        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                                    with col2:\n",
        "                                        st.markdown(f\"\"\"\n",
        "                                        <div class=\"metric-container\">\n",
        "                                            <div class=\"metric-label\">Precision</div>\n",
        "                                            <div class=\"metric-value\">{prec:.2%}</div>\n",
        "                                        </div>\n",
        "                                        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                                    with col3:\n",
        "                                        st.markdown(f\"\"\"\n",
        "                                        <div class=\"metric-container\">\n",
        "                                            <div class=\"metric-label\">Recall</div>\n",
        "                                            <div class=\"metric-value\">{rec:.2%}</div>\n",
        "                                        </div>\n",
        "                                        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                                    with col4:\n",
        "                                        st.markdown(f\"\"\"\n",
        "                                        <div class=\"metric-container\">\n",
        "                                            <div class=\"metric-label\">F1-Score</div>\n",
        "                                            <div class=\"metric-value\">{f1s:.2%}</div>\n",
        "                                        </div>\n",
        "                                        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                                    st.markdown(\"---\")\n",
        "\n",
        "                                    # Matriz de confusi√≥n y reporte\n",
        "                                    col1, col2 = st.columns(2)\n",
        "\n",
        "                                    with col1:\n",
        "                                        st.markdown(\"**üéØ Matriz de Confusi√≥n**\")\n",
        "                                        st.dataframe(\n",
        "                                            pd.DataFrame(\n",
        "                                                cm,\n",
        "                                                columns=['Pred 0', 'Pred 1'],\n",
        "                                                index=['Real 0', 'Real 1']\n",
        "                                            ),\n",
        "                                            use_container_width=True\n",
        "                                        )\n",
        "\n",
        "                                    with col2:\n",
        "                                        st.markdown(\"**üìã Classification Report**\")\n",
        "                                        st.text(report)\n",
        "\n",
        "                                    outdf = X_test.copy()\n",
        "                                    outdf['target'] = y_test\n",
        "                                    outdf['prediction'] = preds\n",
        "                                    if probs is not None and probs.shape[1] == 2:\n",
        "                                        outdf['prob_pos'] = probs[:,1]\n",
        "\n",
        "                                    outdf.to_csv(VALIDATION_EVIDENCE, index=False)\n",
        "                                    st.success(f\"‚úÖ Evidencia guardada en: {VALIDATION_EVIDENCE}\")\n",
        "\n",
        "                                    st.download_button(\n",
        "                                        \"‚¨áÔ∏è Descargar evidencia (CSV)\",\n",
        "                                        data=outdf.to_csv(index=False).encode('utf-8'),\n",
        "                                        file_name='evidencia_validacion_predicciones.csv',\n",
        "                                        mime='text/csv',\n",
        "                                        use_container_width=True\n",
        "                                    )\n",
        "                                except Exception as e:\n",
        "                                    st.error(f\"‚ùå Error al ejecutar la validaci√≥n: {e}\")\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "# Footer mejorado\n",
        "st.markdown(\"---\")\n",
        "with st.expander(\"üìÇ Archivos del sistema\", expanded=False):\n",
        "    file_status = []\n",
        "    for f in [PREDICTIONS_OUT, VALIDATION_EVIDENCE, LOGFILE, MODEL_PATH, DF_TRAIN_PATH]:\n",
        "        status = '‚úÖ Existe' if os.path.exists(f) else '‚ùå No encontrado'\n",
        "        file_status.append({'Archivo': f, 'Estado': status})\n",
        "\n",
        "    st.dataframe(pd.DataFrame(file_status), use_container_width=True, hide_index=True)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; padding: 2rem; color: #666;'>\n",
        "    <p>üí° <strong>Tip:</strong> Para ejecutar la app en Colab: levanta Streamlit y ngrok/localtunnel</p>\n",
        "    <p style='font-size: 0.9rem; margin-top: 1rem;'>Desarrollado con ‚ù§Ô∏è usando Streamlit</p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDdEy2fg_U4J",
        "outputId": "ea318bd0-820a-403b-a5f0-7623c8d1e816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from pyngrok import ngrok, conf\n",
        "import os, time, subprocess, signal\n",
        "\n",
        "# Pega aqu√≠ tu token (reemplaza la cadena)\n",
        "AUTHTOKEN = \"35KjxESoOJSDnKzIglmLBtd2Due_7dmKy39hgYs5ccK1qjgar\"\n",
        "\n",
        "# Guardar el token en la configuraci√≥n de pyngrok\n",
        "!ngrok authtoken {AUTHTOKEN}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTgs8FAN_baR",
        "outputId": "90651e54-a49b-49ec-ec3f-5805ca94a46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "st.title(\"Demo Streamlit\")\n",
        "st.write(\"Coloca aqu√≠ tu app real.\")\n",
        "# Aseg√∫rate de que 'modelo_final_pipeline.pkl' existe en /content si tu app lo usa.\n",
        "\n",
        "# Levantar ngrok al puerto 8501 y mostrar URL p√∫blica\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üåç URL p√∫blica (ngrok):\", public_url)\n",
        "\n",
        "# Iniciar Streamlit en background\n",
        "get_ipython().system_raw('streamlit run app.py --server.port 8501 &')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q7CxwkAAiHa",
        "outputId": "0b5d41fd-29b8-4fc3-9b60-1236fecafb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-11 15:47:21.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-11 15:47:21.789 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-11 15:47:21.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-11 15:47:21.791 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-11 15:47:21.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-11 15:47:21.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåç URL p√∫blica (ngrok): NgrokTunnel: \"https://overplentifully-costless-ardell.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Cerrar t√∫neles previos por si acaso\n",
        "ngrok.kill()\n",
        "\n",
        "# Abrir un nuevo t√∫nel HTTPS al puerto 8501\n",
        "public_url = ngrok.connect(addr=8501, bind_tls=True)\n",
        "print(\"üåç URL p√∫blica (ngrok):\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-jmzRY9BOUD",
        "outputId": "e7d6e4af-02f8-4040-de8c-a6e996bca4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåç URL p√∫blica (ngrok): NgrokTunnel: \"https://overplentifully-costless-ardell.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üî¥ Detener ngrok (t√∫nel p√∫blico)\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "# üî¥ Matar el proceso de Streamlit en el puerto 8501\n",
        "!kill $(lsof -t -i:8501) || true\n",
        "\n",
        "# # Verificar que ya no haya nada usando ese puerto\n",
        "!lsof -i:8501 || echo \"‚úÖ Streamlit detenido correctamente\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIOiGOG3X8vu",
        "outputId": "3783da2c-8093-41b3-ba05-d65cad91fb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND     PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
            "streamlit 42153 root    6u  IPv4 1121863      0t0  TCP *:8501 (LISTEN)\n",
            "streamlit 42153 root    7u  IPv6 1121864      0t0  TCP *:8501 (LISTEN)\n"
          ]
        }
      ]
    }
  ]
}